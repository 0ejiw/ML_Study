{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "P1RBPkHAVanw",
        "vbvHEbkRMDFY",
        "BhvEh5hcMuLv",
        "qbWt7Uq0M5rl",
        "CMh7g8TmVoqo"
      ],
      "authorship_tag": "ABX9TyOP8N2MTsFlMrR8QRVxNdOu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0ejiw/ML_Study/blob/main/%ED%8C%8C%EC%9D%B4%EC%8D%AC_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EC%99%84%EB%B2%BD_%EA%B0%80%EC%9D%B4%EB%93%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 파이썬 기반의 머신러닝과 생태계 이해"
      ],
      "metadata": {
        "id": "P1RBPkHAVanw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slsbwKFU2ujw"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_array=np.arange(3,10)\n",
        "print(seq_array)\n",
        "print(seq_array.dtype, seq_array.shape)"
      ],
      "metadata": {
        "id": "WCq-3VHQBFvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zero_array=np.zeros((3,2))\n",
        "print(zero_array)\n",
        "print(zero_array.dtype, zero_array.shape)"
      ],
      "metadata": {
        "id": "KG8YVVNYBUN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eduf2lmyBj42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 사이킷런으로 시작하는 머신러닝"
      ],
      "metadata": {
        "id": "vbvHEbkRMDFY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. 사이킷런 소개와 특징"
      ],
      "metadata": {
        "id": "BhvEh5hcMuLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "print(sklearn.__version__)"
      ],
      "metadata": {
        "id": "iLNF17-1MSE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. 첫 번째 머신러닝 만들어 보기 - 붓꽃 품종 예측하기"
      ],
      "metadata": {
        "id": "qbWt7Uq0M5rl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "TYC3HPRlMj96"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 붓꽃 데이터 세트 로딩\n",
        "iris = load_iris()\n",
        "\n",
        "# iris.data는 붓꽃 데이터 세트에서 feature data만을 numpy로 가짐\n",
        "iris_data = iris.data\n",
        "\n",
        "# iris.target은 붓꽃 데이터 세트에서 label data만을 numpy로 가짐\n",
        "iris_label = iris.target\n",
        "print('iris target값:', iris_label)\n",
        "print('iris target명:', iris.target_names)"
      ],
      "metadata": {
        "id": "Pj_z5uYjOLM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 붓꽃 데이터 세트를 자세히 보기 위해 DataFrame으로 변환\n",
        "iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)\n",
        "iris_df['label'] = iris.target\n",
        "iris_df"
      ],
      "metadata": {
        "id": "Q7PTXhn2PH0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습용 데이터와 테스트용 데이터 분리\n",
        "feature_train, feature_test, label_train, label_test = train_test_split(iris_data, iris_label, test_size=0.2, random_state=11)"
      ],
      "metadata": {
        "id": "aotGYUzSPnp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DecisionTreeClassifier 객체 생성\n",
        "dt_clf = DecisionTreeClassifier(random_state=11)"
      ],
      "metadata": {
        "id": "BcNDJyFlPgw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 수행\n",
        "dt_clf.fit(feature_train, label_train)"
      ],
      "metadata": {
        "id": "IdVHY6SkQxCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습이 완료된 DTC 객체에서 테스트 데이터 셋으로 예측 수행\n",
        "pred = dt_clf.predict(feature_test)"
      ],
      "metadata": {
        "id": "lBmp7f_2Q2EG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 예측값 반환\n",
        "print(pred)\n",
        "\n",
        "# 테스트 데이터의 label 데이터\n",
        "print(label_test)"
      ],
      "metadata": {
        "id": "otB-2TxrRMDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정확도 평가\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "print('예측 정확도: {0:.4f}'.format(accuracy_score(label_test, pred)))"
      ],
      "metadata": {
        "id": "6CLclCmnQzb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**정리**\n",
        "1. **데이터 세트 분리**: 전체 데이터를 학습 데이터와 테스트 데이터로 분리\n",
        "2. **모델 학습**: 학습 데이터를 활용하여 ML 알고리즘을 적용해 모델 학습\n",
        "3. **예측 수행**: 학습된 모델을 이용해 테스트 데이터 분류 예측\n",
        "4. **평가**: 예측 결과값과 실제 결과값을 비교하여 ML 모델 성능 평가"
      ],
      "metadata": {
        "id": "-Ln5anBiSRcm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oIKj7UQ_R0LW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3. 사이킷런의 기반 프레임워크 익히기"
      ],
      "metadata": {
        "id": "CMh7g8TmVoqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 사이킷런 내장 데이터 세트 구조\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# dict과 비슷한 Bunch 자료형\n",
        "iris_data = load_iris()\n",
        "print(type(iris_data))"
      ],
      "metadata": {
        "id": "Qs1zlqp5Vvmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 붓꽃 데이터 세트의 keys\n",
        "keys = iris_data.keys()\n",
        "print('붓꽃 데이터 세트의 키들:', keys)"
      ],
      "metadata": {
        "id": "E-BFiaFYWIGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# keys 상세\n",
        "\n",
        "# feature_names\n",
        "print('feature_names의 type: ', type(iris_data.feature_names))\n",
        "print('feature_names의 shape: ', len(iris_data.feature_names))\n",
        "print(iris_data.feature_names)\n",
        "\n",
        "# target_names\n",
        "print('\\ntarget_names의 type: ', type(iris_data.target_names))\n",
        "print('target_names의 shape: ', iris_data.target_names.shape)\n",
        "print(iris_data.target_names)\n",
        "\n",
        "# data\n",
        "print('\\ndata의 type: ', type(iris_data.data))\n",
        "print('data의 shape: ', iris_data.data.shape)\n",
        "print(iris_data['data']) # iris_data.data와 동일\n",
        "\n",
        "# target\n",
        "print('\\ntarget의 type: ', type(iris_data.target))\n",
        "print('target의 shape: ', iris_data.target.shape)\n",
        "print(iris_data.target)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "mv0Xs4EqWTm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4. Model Selection 모듈 소개"
      ],
      "metadata": {
        "id": "XJtzDI1gY-WG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 학습/테스트 데이터 세트 분리 - train_test_split()"
      ],
      "metadata": {
        "id": "SACxtPGk2_OZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "8U3Lzd3uW9Sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 붓꼿 데이터 세트 로드\n",
        "iris_data = load_iris()\n",
        "\n",
        "# 의사결정트리 객체 생성\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "\n",
        "# 테스트 데이터와 학습 데이터 분리\n",
        "feature_train, feature_test, label_train, label_test = train_test_split(iris_data.data, iris_data.target, test_size=0.3, random_state=121)"
      ],
      "metadata": {
        "id": "oryQQla70m8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 의사결정트리 알고리즘으로 학습 수행\n",
        "dt_clf.fit(feature_train, label_train)\n",
        "\n",
        "# 예측 진행\n",
        "pred = dt_clf.predict(feature_test)\n",
        "\n",
        "# 정확도 평가\n",
        "print('예측 정확도: {0:.4f}'.format(accuracy_score(label_test, pred)))"
      ],
      "metadata": {
        "id": "ziWyfAH01lA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pred)\n",
        "print(label_test)"
      ],
      "metadata": {
        "id": "herp6kDA2Ky1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 교차 검증"
      ],
      "metadata": {
        "id": "Dgu9Zbv63JKc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "과적합(Overfitting) 문제를 막기 위해서 별도의 여러 세트로 구성된 학습 데이터 세트와 검증 데이터 세트에서 학습과 평가를 수행하는 것"
      ],
      "metadata": {
        "id": "kplOGZUw3OYz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "기존 학습 데이터 세트 중 일부를 검증 데이터 세트로 하여 이를 활용해 모델 성능 1차 평가"
      ],
      "metadata": {
        "id": "1ww6xIOB3zzo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "모든 학습/검증 과정이 완료된 후 테스트 데이터 세트를 이용해 모델 성능 최종 평가"
      ],
      "metadata": {
        "id": "0bgS6RJU4BGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### K Fold cross validation"
      ],
      "metadata": {
        "id": "i8PwaovJ4LwV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "전체 데이터 세트를 K등분하여 K번 만큼 각 폴드 세트에 학습과 검증 평가 반복 수행"
      ],
      "metadata": {
        "id": "thr-6gFG4wLg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "K번의 예측 평가를 평균해서 최종 평가로 반영"
      ],
      "metadata": {
        "id": "uyITCIzu5Fya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import KFold # train_test_split 대신 KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "BHhF9Hf_2UI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris = load_iris()\n",
        "\n",
        "feature = iris.data\n",
        "label = iris.target\n",
        "\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)"
      ],
      "metadata": {
        "id": "0Kk3C2Mk5ZuZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5개의 폴드 세트로 분리하는 KFold 객체\n",
        "kfold = KFold(n_splits=5)\n",
        "\n",
        "# 5번의 폴드 세트별 예측 정확도를 담을 List 객체\n",
        "cv_accuracy = []\n",
        "\n",
        "print('붓꽃 데이터 세트 크기:', feature.shape) # data type of feature is ndarray."
      ],
      "metadata": {
        "id": "HOAcxUNO54zB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_iter = 0\n",
        "\n",
        "# KFold 객체에 split()을 호출하면, 각 폴드별 학습용, 검증용 테스트의 row index가 array로 반환\n",
        "for train_index, test_index in kfold.split(feature):\n",
        "    feature_train, feature_test = feature[train_index], feature[test_index]\n",
        "    label_train, label_test = label[train_index], label[test_index]\n",
        "\n",
        "    # 학습\n",
        "    dt_clf.fit(feature_train, label_train)\n",
        "\n",
        "    # 예측\n",
        "    pred = dt_clf.predict(feature_test)\n",
        "\n",
        "    n_iter += 1\n",
        "\n",
        "    # 폴드별 정확도 측정\n",
        "    accuracy = np.round(accuracy_score(label_test, pred), 4)\n",
        "\n",
        "    # List 객체에 각 폴드별 정확도 기입\n",
        "    cv_accuracy.append(accuracy)\n",
        "\n",
        "    print('\\n#{0} 정확도: {1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'.format(n_iter, accuracy, feature_train.shape[0], feature_test.shape[0]))\n",
        "    print('#{0} 검증 데이터 세트 인덱스: {1}'.format(n_iter, test_index))\n",
        "\n",
        "# 평균 정확도 평가\n",
        "print('\\n평균 검증 정확도: ', np.mean(cv_accuracy))"
      ],
      "metadata": {
        "id": "trlQAlVm6al2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stratified K Fold cross validation"
      ],
      "metadata": {
        "id": "LgqShrK_9LSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "특정 label data가 매우 많은, 불균형한 분포도를 가진 label dataset을 위한 K Fold 방식"
      ],
      "metadata": {
        "id": "AumuJZqb9c0R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "원본 데이터의 label data 분포를 먼저 고려한 뒤, 이 분포와 동일하게 학습과 검증 데이터 세트를 분배"
      ],
      "metadata": {
        "id": "TV-UM7xM9368"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "iris_df['label'] = iris.target\n",
        "iris_df['label'].value_counts()"
      ],
      "metadata": {
        "id": "dBwRYAUl-ryP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K Fold 방식으로 K=3으로 하면, 첫 번째 검증 데이터는 Label이 모두 0, 두 번째는 1, 세 번째는 2만 존재"
      ],
      "metadata": {
        "id": "9Yz1uN8x__D0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=3)\n",
        "n_iter = 0\n",
        "for train_index, test_index in kfold.split(iris_df):\n",
        "    n_iter += 1\n",
        "    label_train = iris_df['label'].iloc[train_index]\n",
        "    label_test = iris_df['label'].iloc[test_index]\n",
        "\n",
        "    print('## 교차 검증: {0}'.format(n_iter))\n",
        "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
        "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())\n",
        "    print('\\n')"
      ],
      "metadata": {
        "id": "HRG4bulyAjpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "예측 정확도 = 0"
      ],
      "metadata": {
        "id": "EAXm8SvfAPce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "n_iter = 0\n",
        "\n",
        "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
        "    n_iter += 1\n",
        "\n",
        "    label_train = iris_df['label'].iloc[train_index]\n",
        "    label_test = iris_df['label'].iloc[test_index]\n",
        "\n",
        "    print('# 교차 검증: {0}'.format(n_iter))\n",
        "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
        "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())\n",
        "    print('\\n')"
      ],
      "metadata": {
        "id": "vQS5Kp5e_4xe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=3)\n",
        "n_iter = 0\n",
        "cv_accuracy = []\n",
        "\n",
        "for train_index, test_index in skfold.split(feature, label):\n",
        "    feature_train, feature_test = feature[train_index], feature[test_index]\n",
        "    label_train, label_test = label[train_index], label[test_index]\n",
        "\n",
        "    dt_clf.fit(feature_train, label_train)\n",
        "    pred = dt_clf.predict(feature_test)\n",
        "\n",
        "    n_iter += 1\n",
        "    accuracy = np.round(accuracy_score(label_test, pred), 4)\n",
        "    cv_accuracy.append(accuracy)\n",
        "\n",
        "    train_size = feature_train.shape[0]\n",
        "    test_size = feature_test.shape[0]\n",
        "\n",
        "    print('\\n#{0} 교차 검증 정확도: {1}, 학습 데이터 크기: {2}, 검증 데이터 크기:{3}'.format(n_iter, accuracy, train_size, test_size))\n",
        "\n",
        "print('\\n## 교차 검증별 정확도:', np.round(cv_accuracy, 4))\n",
        "print('## 평균 검증 정확도: ', np.round(np.mean(cv_accuracy),4))"
      ],
      "metadata": {
        "id": "EB9wJ8VwB0wP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 교차 검증을 보다 간편하게 - cross_val_score()"
      ],
      "metadata": {
        "id": "4WPd7OY3EiMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "iris = load_iris()\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "feature = iris.data\n",
        "label = iris.target\n",
        "\n",
        "# for문 필요 없이 그냥 한 줄로 끝남\n",
        "scores = cross_val_score(dt_clf, feature, label, scoring='accuracy', cv=3)\n",
        "\n",
        "print('교차 검증별 정확도: ', np.round(scores, 4))\n",
        "print('평균 검증 정확도: ', np.round(np.mean(scores),4))"
      ],
      "metadata": {
        "id": "bJt5kZ5nDjuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GridSearchCV - 교차 검증과 최적 하이퍼 파라미터 튜닝을 한 번에"
      ],
      "metadata": {
        "id": "jXJ8ppsxHdLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "\n",
        "# 데이터 로딩 및 학습/테스트 데이터 분리\n",
        "iris = load_iris()\n",
        "feature_train, feature_test, label_train, label_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=121)\n",
        "\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "\n",
        "# 파라미터를 딕셔너리 형태로 설정\n",
        "parameters = {'max_depth':[1,2,3], 'min_samples_split':[2,3]}"
      ],
      "metadata": {
        "id": "YiNDj1MqF30_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "grid_dt = GridSearchCV(dt_clf, param_grid=parameters, cv=3, refit=True)\n",
        "\n",
        "# 학습/평가\n",
        "grid_dt.fit(feature_train, label_train)\n",
        "\n",
        "# 결과 분석\n",
        "scores_df = pd.DataFrame(grid_dt.cv_results_)\n",
        "scores_df[['params', 'mean_test_score', 'rank_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score']]"
      ],
      "metadata": {
        "id": "O2edzdLNJayr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('GridSearchCV 최적 파라미터: ', grid_dt.best_params_)\n",
        "print('GridSearchCV 최고 정확도: {0:.4f}'.format(grid_dt.best_score_))"
      ],
      "metadata": {
        "id": "rqQTpIeyKZY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GridSearchCV의 refit으로 이미 학습된 estimator 반환\n",
        "estimator = grid_dt.best_estimator_\n",
        "\n",
        "pred = estimator.predict(feature_test)\n",
        "print('테스트 데이터 세트 정확도: {0:.4f}'.format(accuracy_score(label_test, pred)))"
      ],
      "metadata": {
        "id": "dkR8AnigLVGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5. 데이터 전처리"
      ],
      "metadata": {
        "id": "3R-YmbG2MZhU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 데이터 인코딩"
      ],
      "metadata": {
        "id": "M3VIuBGCNsBc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 레이블 인코딩"
      ],
      "metadata": {
        "id": "lCeKIO1GNvj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
        "\n",
        "# LabelEncoder 객체 생성 후, fit()과 transform()으로 레이블 인코딩 수행\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(items)\n",
        "labels = encoder.transform(items)\n",
        "print('인코딩 변환값: ', labels)"
      ],
      "metadata": {
        "id": "TDGbd7uaNxx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터가 많은 경우, 이걸 확인해서 순서대로 0부터 시작하는 것 확인\n",
        "print('인코딩 클래스: ', encoder.classes_)"
      ],
      "metadata": {
        "id": "b4pvV763OiMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 디코딩\n",
        "print('디코딩 원본값: ', encoder.inverse_transform([4,5,2,0,1,1,3,3]))"
      ],
      "metadata": {
        "id": "P0-0T0-ZOvOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 원-핫 인코딩"
      ],
      "metadata": {
        "id": "SKW4mafPR_Yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import numpy as np\n",
        "\n",
        "items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']\n",
        "\n",
        "# 2차원 ndarray로 변환\n",
        "items = np.array(items).reshape(-1,1)\n",
        "\n",
        "# 원핫 인코딩 적용\n",
        "oh_encoder = OneHotEncoder()\n",
        "oh_encoder.fit(items)\n",
        "oh_labels = oh_encoder.transform(items)\n",
        "\n",
        "# sparse matrix이므로 toarray() 통해 dense matrix로 변환\n",
        "print('원-핫 인코딩 데이터')\n",
        "print(oh_labels.toarray())\n",
        "print('원-핫 인코딩 데이터 차원')\n",
        "print(oh_labels.shape)"
      ],
      "metadata": {
        "id": "LcurIs4SPFMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 더 쉽게 원-핫 인코딩 수행\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({'items':['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']})\n",
        "pd.get_dummies(df)"
      ],
      "metadata": {
        "id": "-asl8tAuRHAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 피처 스케일링과 정규화"
      ],
      "metadata": {
        "id": "or2eQCYxSiNU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### StandardScaler"
      ],
      "metadata": {
        "id": "Cl-U-1y_T7mV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "\n",
        "print('feature 들의 평균 값')\n",
        "print(iris_df.mean())\n",
        "print('\\nfeature 들의 분산 값')\n",
        "print(iris_df.var())"
      ],
      "metadata": {
        "id": "4PFzso6NSS7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# StandardScaler 객체 생성\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# StandardScaler 객체로 feature 데이터 세트 변환\n",
        "scaler.fit(iris_df)\n",
        "iris_scaled = scaler.transform(iris_df)\n",
        "\n",
        "iris_scaled_df = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
        "\n",
        "print(iris_scaled)\n",
        "\n",
        "print('feature 들의 평균 값')\n",
        "print(iris_scaled_df.mean())\n",
        "print('\\nfeature 들의 분산 값')\n",
        "print(iris_scaled_df.var())"
      ],
      "metadata": {
        "id": "YVhgJ9EwUbne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MinMaxScaler"
      ],
      "metadata": {
        "id": "F5Mm_0UiWd7l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# MinMaxScaler 객체 생성\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# MinMaxScaler 객체로 feature 데이터 세트 변환\n",
        "scaler.fit(iris_df)\n",
        "iris_scaled = scaler.transform(iris_df)\n",
        "\n",
        "iris_scaled_df = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)\n",
        "\n",
        "print(iris_scaled)\n",
        "\n",
        "print('feature 들의 최솟값')\n",
        "print(iris_scaled_df.min())\n",
        "print('\\nfeature 들의 최댓값')\n",
        "print(iris_scaled_df.max())"
      ],
      "metadata": {
        "id": "lcQxEbeUVuez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 학습 데이터와 테스트 데이터의 스케일링 변환 시 유의점"
      ],
      "metadata": {
        "id": "xnTmn5efYZcQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "train_array = np.arange(0,11).reshape(-1,1)\n",
        "test_array = np.arange(0,6).reshape(-1,1)"
      ],
      "metadata": {
        "id": "AE0uEOeyYg7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NV9_N0scYvYB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}